{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Language Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Watson Developer Cloud, import libraries, and load train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: watson_developer_cloud in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages\n",
      "Requirement not upgraded as not directly required: Twisted>=13.2.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: python-dateutil>=2.5.3 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: pyOpenSSL>=16.2.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: requests<3.0,>=2.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: service-identity>=17.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: autobahn>=0.10.9 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: incremental>=16.10.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from Twisted>=13.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: Automat>=0.3.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from Twisted>=13.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: attrs>=17.4.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from Twisted>=13.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: zope.interface>=4.4.2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from Twisted>=13.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: PyHamcrest>=1.9.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from Twisted>=13.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: hyperlink>=17.1.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from Twisted>=13.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: constantly>=15.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from Twisted>=13.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: six>=1.5 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from python-dateutil>=2.5.3->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: cryptography>=2.2.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pyOpenSSL>=16.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests<3.0,>=2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: idna<2.7,>=2.5 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests<3.0,>=2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: urllib3<1.23,>=1.21.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests<3.0,>=2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: certifi>=2017.4.17 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests<3.0,>=2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: pyasn1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from service-identity>=17.0.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: pyasn1-modules in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from service-identity>=17.0.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: txaio>=18.7.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from autobahn>=0.10.9->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: setuptools in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from zope.interface>=4.4.2->Twisted>=13.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: asn1crypto>=0.21.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from cryptography>=2.2.1->pyOpenSSL>=16.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: cffi>=1.7 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from cryptography>=2.2.1->pyOpenSSL>=16.2.0->watson_developer_cloud)\n",
      "Requirement not upgraded as not directly required: pycparser in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from cffi>=1.7->cryptography>=2.2.1->pyOpenSSL>=16.2.0->watson_developer_cloud)\n",
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Running setup.py bdist_wheel for wget ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade watson_developer_cloud\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import wget\n",
    "import base64\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from collections import *\n",
    "from os.path import isfile, join\n",
    "from watson_developer_cloud import NaturalLanguageClassifierV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget.download( 'https://github.com/IBM/programming-language-classifier/blob/master/data/githubtrainingdatacompressed.npz?raw=true' )\n",
    "wget.download( 'https://github.com/IBM/programming-language-classifier/blob/master/data/githubtestdatacompressed.npz?raw=true' )\n",
    "\n",
    "train_data = np.array(np.load(\"githubtrainingdatacompressed.npz\")['arr_0'])\n",
    "test_data = np.array(np.load(\"githubtestdatacompressed.npz\")['arr_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little more preprocessing\n",
    "\n",
    "break the training data into separate dictionaries indexed by pl type, and map training data to a csv for Watson (my csv is on GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = {}\n",
    "for row in range(len(train_data)):\n",
    "    if train_data[row][1].decode() not in pls:\n",
    "        pls[train_data[row][1].decode()] = []\n",
    "    pls[train_data[row][1].decode()].append(train_data[row][0].decode())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CSV cannot exceed 1024 characters for column width and 15000 rows. So each piece of code is pushed into a Pandas dataframe in at most 1024 character chunks. Watson cannot take empty column values either, so those are removed, then the dataframe is converted into a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "chunk = 1024\n",
    "\n",
    "for i in train_data:\n",
    "        for j in range(0,len(i[0]),chunk):\n",
    "            text = re.sub(' +',' ',\" \".join(re.split(r'[^\\w]', re.sub(re.compile(\"/\\*.*?\\*/\",re.DOTALL ) ,\"\" ,i[0][j:j+chunk].decode('utf-8')))))   \n",
    "            d.append({'text': text, 'pl': i[1].decode()})\n",
    "\n",
    "df = pd.DataFrame(d, columns = ['text', 'pl'])\n",
    "df['text'].replace(' ', np.nan, inplace=True)\n",
    "df = df.dropna()\n",
    "df.to_csv('trainingdata.csv', header=['text','pl'],index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "Here we train a Naive Bayes Classifier\n",
    "for a light review on Naive Bayes look through the slides on GitHub\n",
    "for a thorough background on this topic (and many others in Machine Learning) \n",
    "check out Tom Mitchell's Carnegie Mellon course \n",
    "http://cc-web.isri.cmu.edu/CourseCast/Viewer/Default.aspx?id=a666b6e6-ad23-4fa3-96ce-ae50a42f45a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bayes_train(pldict, samples):\n",
    "    plprobs = {}\n",
    "    counts = Counter()\n",
    "    for i in pldict:\n",
    "        plprobs[i] = float(len(pldict[i]))/samples\n",
    "        \n",
    "    plwordprobs = {}\n",
    "    plwordcounts = {}\n",
    "    for pl in pldict:\n",
    "        plwordprobs[pl] = {}\n",
    "        plwordcounts[pl] = 0\n",
    "    \n",
    "    for pl in pldict:\n",
    "        for i in pldict[pl]:\n",
    "            counts.update(filter(None, re.split(r'[^\\w]', re.sub(re.compile(\"/\\*.*?\\*/\",re.DOTALL ) ,\"\" ,i))))\n",
    "            for word in counts:\n",
    "                if word not in plwordprobs[pl]:\n",
    "                    plwordprobs[pl][word] = counts[word]\n",
    "                else:\n",
    "                    plwordprobs[pl][word] += counts[word]\n",
    "                plwordcounts[pl] += counts[word]\n",
    "            plwordcount = 0\n",
    "            counts = Counter()\n",
    "    for pl in plwordprobs:   \n",
    "        for word in plwordprobs[pl]:\n",
    "            plwordprobs[pl][word] = float(plwordprobs[pl][word])/plwordcounts[pl]\n",
    "        \n",
    "    \n",
    "    return plprobs, plwordprobs\n",
    "    \n",
    "plprobs, plwordprobs = bayes_train(pls, len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the distribution of programming languages in our training set, and 10 of the most commonly used words of a particular language, try replacing 'sh' with other languages and observe the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 0.04184782608695652,\n",
       " 'java': 0.2184782608695652,\n",
       " 'js': 0.20597826086956522,\n",
       " 'm': 0.06956521739130435,\n",
       " 'py': 0.07880434782608696,\n",
       " 'sh': 0.17771739130434783,\n",
       " 'swift': 0.175,\n",
       " 'xml': 0.03260869565217391}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('echo', 0.03864587716931944),\n",
       " ('the', 0.03778674579624146),\n",
       " ('0', 0.033368860713964506),\n",
       " ('1', 0.030890171747144934),\n",
       " ('if', 0.02780092617570351),\n",
       " ('for', 0.027205853790126674),\n",
       " ('import', 0.02685395198273526),\n",
       " ('to', 0.02617263735275594),\n",
       " ('in', 0.02470367772682303),\n",
       " ('return', 0.023925887959715765)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(plwordprobs['sh'].items(), key=operator.itemgetter(1) ,reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Naive Bayes Classifier to predict on the test set, again use the CMU course as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testbayes(testdata,plprob,plwordprob):\n",
    "    Ypred = []\n",
    "\n",
    "    for row in testdata:\n",
    "        testcounter = Counter()\n",
    "        testcounter.update(filter(None, re.split(r'[^\\w]', re.sub(re.compile(\"/\\*.*?\\*/\",re.DOTALL ) ,\"\" ,str(row[0])))))\n",
    "\n",
    "        prob = {}\n",
    "        for key in plprob:\n",
    "            prob[key] = 0\n",
    "        for key in prob:\n",
    "            for i in testcounter:\n",
    "                if i not in plwordprobs[key]:\n",
    "                    plwordprob[key][i] = 1e-4\n",
    "                else:\n",
    "                    plwordprob[key][i] += 1e-4\n",
    "                prob[key] += testcounter[i]*np.log(plwordprob[key][i])\n",
    "            prob[key] += np.log(plprob[key])\n",
    "        Ypred.append(max(prob.items(), key=operator.itemgetter(1))[0])\n",
    "    \n",
    "    return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = testbayes(test_data, plprobs, plwordprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Watson and Evaluating Classification Accuracy\n",
    "\n",
    "Autherticate with Watson, send it the training data csv, wait for it to finish its training phase, and compute the accuarcy of both models. \n",
    "\n",
    "My results are displayed below. Let me know what you get at nacosta@us.ibm.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "natural_language_classifier = NaturalLanguageClassifierV1(\n",
    "    username=\"YOURUSERNAME\",\n",
    "    password=\"YOURPASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Programming Language Classifier\",\n",
      "  \"classifier_id\": \"3b08fex552-nlc-1263\",\n",
      "  \"url\": \"https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/3b08fex552-nlc-1263\",\n",
      "  \"language\": \"en\",\n",
      "  \"status_description\": \"The classifier instance is in its training phase, not yet ready to accept classify requests\",\n",
      "  \"created\": \"2018-08-23T17:52:43.060Z\",\n",
      "  \"status\": \"Training\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('trainingdata.csv', 'rb') as training_data:\n",
    "    print(json.dumps(natural_language_classifier.create_classifier(training_data=training_data, metadata='{\"name\": \"Programming Language Classifier\",\"language\": \"en\"}'), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy/Paste your classifier_id into the variable below. In the above example, \"3b08fex552-nlc-1263\" would be used. Monitor the status of your classifer be using the API below. Once the classifier's \"status_description\" matches the example below, proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_id = \"YOURCLASSIFIERID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier_id': '3b08fex552-nlc-1263',\n",
       " 'created': '2018-08-23T17:52:43.060Z',\n",
       " 'language': 'en',\n",
       " 'name': 'Programming Language Classifier',\n",
       " 'status': 'Training',\n",
       " 'status_description': 'The classifier instance is in its training phase, not yet ready to accept classify requests',\n",
       " 'url': 'https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/3b08fex552-nlc-1263'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_language_classifier.get_classifier(classifier_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'classifier_id': u'3b08fex552-nlc-1263',\n",
       " u'created': u'2018-08-23T17:52:43.060Z',\n",
       " u'language': u'en',\n",
       " u'name': u'Programming Language Classifier',\n",
       " u'status': u'Available',\n",
       " u'status_description': u'The classifier instance is now available and is ready to take classifier requests.',\n",
       " u'url': u'https://gateway.watsonplatform.net/natural-language-classifier/api/v1/classifiers/ee2ec4x254-nlc-4275'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_language_classifier.get_classifier(\"classifier_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_my_accuracy(pred, testdata):\n",
    "    count = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == testdata[i][1].decode():\n",
    "            count += 1\n",
    "    return float(count)/len(pred)\n",
    "\n",
    "def compute_watson_accuracy(pred, testdata):\n",
    "    count = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == testdata[i][1].decode():\n",
    "            count += 1\n",
    "    return float(count)/len(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watsonpred = []\n",
    "for i in test_data:\n",
    "    x = natural_language_classifier.classify(classifier_id,re.sub(' +',' ',\" \".join(re.split(r'[^\\w]', re.sub(re.compile(\"/\\*.*?\\*/\",re.DOTALL ) ,\"\" ,i[0].decode()))))[0:1024])\n",
    "    watsonpred.append(x['top_class'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"My classifier's accuracy: \" + str(compute_my_accuracy(predictions, test_data)))\n",
    "print(\"Watson's accuracy: \" + str(compute_watson_accuracy(watsonpred, test_data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
